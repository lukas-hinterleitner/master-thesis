{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:32.832260Z",
     "start_time": "2025-08-04T18:23:32.829777Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from src.model import get_model, get_tokenizer\n",
    "from src.dataset import get_paraphrased_dataset_tokenized"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:32.883135Z",
     "start_time": "2025-08-04T18:23:32.880447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "524a4eae9f8afa6f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:33.110843Z",
     "start_time": "2025-08-04T18:23:32.931273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "5e0fe7a9a19ec85d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3047"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:33.133667Z",
     "start_time": "2025-08-04T18:23:33.131582Z"
    }
   },
   "cell_type": "code",
   "source": "model_name = \"amd/AMD-OLMo-1B-SFT\"",
   "id": "ec6e5c857cd2d116",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:34.433201Z",
     "start_time": "2025-08-04T18:23:33.180617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_model(model_name, torch.device(\"cpu\"))\n",
    "tokenizer = get_tokenizer(model_name)"
   ],
   "id": "bcb037724eaed310",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Model parameters: 1176764416\n",
      "==================================================\n",
      "OlmoForCausalLM(\n",
      "  (model): OlmoModel(\n",
      "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x OlmoDecoderLayer(\n",
      "        (self_attn): OlmoAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): OlmoMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): OlmoLayerNorm()\n",
      "        (post_attention_layernorm): OlmoLayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): OlmoLayerNorm()\n",
      "    (rotary_emb): OlmoRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:53.907704Z",
     "start_time": "2025-08-04T18:23:53.870943Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_sample_0_tokenized = get_paraphrased_dataset_tokenized(model, tokenizer, sample_size=1)[0]",
   "id": "edd78f75f545424d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T18:23:57.298177Z",
     "start_time": "2025-08-04T18:23:57.289442Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_sample_0_tokenized",
   "id": "61469684c535c07b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'lima_0',\n",
       " 'paraphrased_messages': [{'content': \"Are brain cells capable of moving? Specifically, I'm referring to long-distance migration, ideally occurring within the brain.\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'The inquiry is quite extensive, and it’s important to recognize that the brain is made up not only of neurons but also of glial cells (supporting cells) and pre-mitotic neuronal stem cells. Additionally, as critical colleagues in research have pointed out, the developmental stage is crucial, since the developing embryonic brain is significantly different from the fully developed adult brain. Nonetheless, after reviewing various studies, the answer to the question turns out to be surprisingly straightforward: Yes, brain cells do migrate. In the adult brain, glial cells are known to migrate (Klämbt, 2009). These glial cells perform numerous functions, with a prominent example being oligodendrocytes, which migrate over considerable distances to locate their target axons and encase them to create the insulating myelin sheath (Tsai and Miller, 2002). Neuronal stem cells also migrate long distances in response to injury (Imitola et al., 2004), moving from specific stem-cell areas (such as the hippocampus and subventricular zone) to other parts of the brain (Clarke, 2003). It has been demonstrated that post-mitotic but non-differentiated neurons can migrate within the adult brain in fish (Scott et al., 2012) and also in mammals and non-human primates (Sawada et al., 2011). Unsurprisingly, glial cells, stem cells, and neurons also undergo migration during embryonic development. Most notably, post-mitotic neurons that are intended for peripheral roles must migrate over relatively long distances from the neural crest to their designated target areas (Neuroscience, 2nd ed, Neuronal Migration).',\n",
       "   'role': 'assistant'}],\n",
       " 'input_ids_prompt': tensor([   29,    93,  4537, 49651,   187,  6723,  3998,  1341,  7032,   273,\n",
       "          4886,    32, 13658,    13,   309,  1353, 14339,   281,  1048,    14,\n",
       "         19893, 10346,    13, 34243, 12952,  1561,   253,  3998,    15,   187,\n",
       "            29,    93,   515,  5567, 49651,   187]),\n",
       " 'input_ids': tensor([   29,    93,  4537, 49651,   187,  6723,  3998,  1341,  7032,   273,\n",
       "          4886,    32, 13658,    13,   309,  1353, 14339,   281,  1048,    14,\n",
       "         19893, 10346,    13, 34243, 12952,  1561,   253,  3998,    15,   187,\n",
       "            29,    93,   515,  5567, 49651,   187,   510, 14392,   310,  3240,\n",
       "          9470,    13,   285,   352,   457,    84,  1774,   281,  9446,   326,\n",
       "           253,  3998,   310,  1160,   598,   417,   760,   273,  8512,   533,\n",
       "           671,   273, 42782,  1341,   313,  4032, 12655,  1341,    10,   285,\n",
       "           638,    14,  2225,  3875, 16069,  8424,  1341,    15,  9157,    13,\n",
       "           347,  4619, 11651,   275,  2561,   452,  8042,   562,    13,   253,\n",
       "         16743,  3924,   310,  9560,    13,  1580,   253,  6684, 24022,  3998,\n",
       "           310,  3012,  1027,   432,   253,  4751,  3715,  6782,  3998,    15,\n",
       "         24883,    13,   846, 16725,  2710,  2175,    13,   253,  3662,   281,\n",
       "           253,  1953,  7819,   562,   281,   320, 19143, 15246,    27,  6279,\n",
       "            13,  3998,  1341,   513, 31690,    15,   496,   253,  6782,  3998,\n",
       "            13, 42782,  1341,   403,  1929,   281, 31690,   313,    44, 42824,\n",
       "          1814,    85,    13,  4748,   481,  2053, 42782,  1341,  1347,  7418,\n",
       "          3470,    13,   342,   247, 11906,  1650,  1146, 13081, 45813, 20158,\n",
       "            13,   534, 31690,   689, 10665, 13849,   281, 19912,   616,  2303,\n",
       "         41382,   285,  2349,   511,   731,   281,  2794,   253, 22831, 16203,\n",
       "           249, 30334,   313, 27415,  2284,   285, 11418,    13,  6752,   481,\n",
       "          3532,   321,  2814,  8424,  1341,   671, 31690,  1048, 13849,   275,\n",
       "          2380,   281,  4975,   313,    42,  2225,  6836,  1162,   355,   904,\n",
       "          6157,   582,  4886,   432,  2173,  8424,    14,  3992,  3672,   313,\n",
       "         10328,   347,   253, 26382,   285,   749,  2254, 13267,  8232,    10,\n",
       "           281,   643,  4243,   273,   253,  3998,   313,  2019,   274,   413,\n",
       "            13,  6469,   481,   733,   556,   644,  5183,   326,  1501,    14,\n",
       "          2225,  3875,   533,  1327,    14, 19623,  4215,  8512,   476, 31690,\n",
       "          1561,   253,  6782,  3998,   275,  6773,   313, 22384,  1162,   355,\n",
       "           904,  4050,    10,   285,   671,   275, 25045,   285,  1327,    14,\n",
       "         13961, 47063,   313,    52,  1403,  2960,  1162,   355,   904,  4332,\n",
       "           481,   914,  9960, 28761,    13, 42782,  1341,    13,  8424,  1341,\n",
       "            13,   285,  8512,   671, 15080, 10346,  1309, 24022,  2440,    15,\n",
       "          5595, 19836,    13,  1501,    14,  2225,  3875,  8512,   326,   403,\n",
       "          6034,   323, 10844,  9503,  1364, 31690,   689,  4942,  1048, 13849,\n",
       "           432,   253, 11454, 30402,   281,   616, 13205,  2303,  3672,   313,\n",
       "          6560,  1822, 21559,    13,   374,  2109,  1407,    13,  3532,   321,\n",
       "          2814, 49063,   481, 50279]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]),\n",
       " 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,   510, 14392,   310,  3240,\n",
       "          9470,    13,   285,   352,   457,    84,  1774,   281,  9446,   326,\n",
       "           253,  3998,   310,  1160,   598,   417,   760,   273,  8512,   533,\n",
       "           671,   273, 42782,  1341,   313,  4032, 12655,  1341,    10,   285,\n",
       "           638,    14,  2225,  3875, 16069,  8424,  1341,    15,  9157,    13,\n",
       "           347,  4619, 11651,   275,  2561,   452,  8042,   562,    13,   253,\n",
       "         16743,  3924,   310,  9560,    13,  1580,   253,  6684, 24022,  3998,\n",
       "           310,  3012,  1027,   432,   253,  4751,  3715,  6782,  3998,    15,\n",
       "         24883,    13,   846, 16725,  2710,  2175,    13,   253,  3662,   281,\n",
       "           253,  1953,  7819,   562,   281,   320, 19143, 15246,    27,  6279,\n",
       "            13,  3998,  1341,   513, 31690,    15,   496,   253,  6782,  3998,\n",
       "            13, 42782,  1341,   403,  1929,   281, 31690,   313,    44, 42824,\n",
       "          1814,    85,    13,  4748,   481,  2053, 42782,  1341,  1347,  7418,\n",
       "          3470,    13,   342,   247, 11906,  1650,  1146, 13081, 45813, 20158,\n",
       "            13,   534, 31690,   689, 10665, 13849,   281, 19912,   616,  2303,\n",
       "         41382,   285,  2349,   511,   731,   281,  2794,   253, 22831, 16203,\n",
       "           249, 30334,   313, 27415,  2284,   285, 11418,    13,  6752,   481,\n",
       "          3532,   321,  2814,  8424,  1341,   671, 31690,  1048, 13849,   275,\n",
       "          2380,   281,  4975,   313,    42,  2225,  6836,  1162,   355,   904,\n",
       "          6157,   582,  4886,   432,  2173,  8424,    14,  3992,  3672,   313,\n",
       "         10328,   347,   253, 26382,   285,   749,  2254, 13267,  8232,    10,\n",
       "           281,   643,  4243,   273,   253,  3998,   313,  2019,   274,   413,\n",
       "            13,  6469,   481,   733,   556,   644,  5183,   326,  1501,    14,\n",
       "          2225,  3875,   533,  1327,    14, 19623,  4215,  8512,   476, 31690,\n",
       "          1561,   253,  6782,  3998,   275,  6773,   313, 22384,  1162,   355,\n",
       "           904,  4050,    10,   285,   671,   275, 25045,   285,  1327,    14,\n",
       "         13961, 47063,   313,    52,  1403,  2960,  1162,   355,   904,  4332,\n",
       "           481,   914,  9960, 28761,    13, 42782,  1341,    13,  8424,  1341,\n",
       "            13,   285,  8512,   671, 15080, 10346,  1309, 24022,  2440,    15,\n",
       "          5595, 19836,    13,  1501,    14,  2225,  3875,  8512,   326,   403,\n",
       "          6034,   323, 10844,  9503,  1364, 31690,   689,  4942,  1048, 13849,\n",
       "           432,   253, 11454, 30402,   281,   616, 13205,  2303,  3672,   313,\n",
       "          6560,  1822, 21559,    13,   374,  2109,  1407,    13,  3532,   321,\n",
       "          2814, 49063,   481, 50279])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2a5ece0fb0b53a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
