pyxis: importing docker image: lukashinterleitner/master-thesis-data-science:latest
pyxis: imported docker image: lukashinterleitner/master-thesis-data-science:latest
[2025-05-21 11:32:53,540] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /srv/home/users/a51912219cs/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Setting: paraphrased
Computation Type: gradient-similarity
Use Random Projection: True
Device: cuda:0
Model parameters: 124439808
======================
GPT2LMHeadModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2Attention(
          (c_attn): Conv1D(nf=2304, nx=768)
          (c_proj): Conv1D(nf=768, nx=768)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D(nf=3072, nx=768)
          (c_proj): Conv1D(nf=768, nx=3072)
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50257, bias=False)
)
Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors
Calculating gradients + similarities using random projection:   0%|          | 0/988 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
Calculating gradients + similarities using random projection:   0%|          | 0/988 [00:00<?, ?it/s]
Projection dimension: 1244398
Paraphrased gradient shape: torch.Size([124439808])
Paraphrased gradient reshaped shape: torch.Size([1, 124439808])
Traceback (most recent call last):
  File "/app/main.py", line 184, in <module>
    main()
  File "/app/main.py", line 125, in main
    gradient_similarities = calculate_paraphrased_random_projected_gradient_similarities(
  File "/app/application/computation.py", line 232, in calculate_paraphrased_random_projected_gradient_similarities
    down_projected_paraphrased_gradient = projector.project(
  File "/usr/local/lib/python3.10/dist-packages/trak/projectors.py", line 408, in project
    result = fn(
ValueError: Invalid Number of JL dimensions it has to be a multiple of 512
